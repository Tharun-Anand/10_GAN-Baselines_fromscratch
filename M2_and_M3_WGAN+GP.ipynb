{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c791224974d4e7b85ac173c77c38f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7656f9728404a429d37f00e6b086daa",
              "IPY_MODEL_6c7b493e5017482db645b1be07f9b067",
              "IPY_MODEL_c03a63f1287a43b3913cd5d575a81b88"
            ],
            "layout": "IPY_MODEL_a3e54ca7a5f040ec9d9b1d6279b23eca"
          }
        },
        "d7656f9728404a429d37f00e6b086daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_854ea0ab6cca4be6954fdb708dc72d31",
            "placeholder": "​",
            "style": "IPY_MODEL_3a7e361a16e64bcab2feba934b65598e",
            "value": "Epoch 1:  61%"
          }
        },
        "6c7b493e5017482db645b1be07f9b067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e68cf24c149c4312bb3182129fa193d8",
            "max": 938,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f3754ac6afb45d395bbb1ffb7fcb10d",
            "value": 575
          }
        },
        "c03a63f1287a43b3913cd5d575a81b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f5dfc0839144c1bb12fa1ae937b37b1",
            "placeholder": "​",
            "style": "IPY_MODEL_a314f70cf9eb438fb82486b1f6ec32d4",
            "value": " 575/938 [00:42&lt;00:27, 13.38it/s, v_num=mq9k, g_loss_step=-3.51, d_loss_step=2.280, g_loss_epoch=-6.57, d_loss_epoch=3.480]"
          }
        },
        "a3e54ca7a5f040ec9d9b1d6279b23eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "854ea0ab6cca4be6954fdb708dc72d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7e361a16e64bcab2feba934b65598e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e68cf24c149c4312bb3182129fa193d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f3754ac6afb45d395bbb1ffb7fcb10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f5dfc0839144c1bb12fa1ae937b37b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a314f70cf9eb438fb82486b1f6ec32d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Wasserstein Generative Adversarial Network"
      ],
      "metadata": {
        "id": "jJnqDELD8t1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main Improvements:**\n",
        "\n",
        "1. Earth Mover's Distance (Remove Sigmoid Layer from D).  \n",
        "2. Weight Clipping after every optimizer step.  "
      ],
      "metadata": {
        "id": "_xp_Q0GbaM1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "BKl81qZA8yvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### wandb (interactive cell)"
      ],
      "metadata": {
        "id": "HNGGKEk680T9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "RL25Wf7N7U3d",
        "outputId": "ce24dbe0-3ac4-40b1-dcb8-6684565fa27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip -qqq install wandb pytorch-lightning torchmetrics > /dev/null\n",
        "\n",
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "wandb.login()\n",
        "\n",
        "# API Key:\n",
        "# d926baa25b6a14ffa4e5c30a6f3bbffbeca8fcf1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lightning"
      ],
      "metadata": {
        "id": "2fYiQ8KT93mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import lightning.pytorch as pl\n",
        "except:\n",
        "  print(\"[!] Couldn't find pytorch-lightning.\\nInstalling it...\\n\")\n",
        "  !pip install lightning > /dev/null\n",
        "  import lightning.pytorch as pl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l72VnqKx946V",
        "outputId": "2de561ee-21d7-46c3-d4a3-278b5432010a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[!] Couldn't find pytorch-lightning.\n",
            "Installing it...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.utilities.model_summary import ModelSummary"
      ],
      "metadata": {
        "id": "2f6GKjlv97Hk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import seed_everything"
      ],
      "metadata": {
        "id": "aW1Wbm2298Km"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### standard imports"
      ],
      "metadata": {
        "id": "t1EQePfV83O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "6AevVvdl85Um"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torchvision.utils import make_grid"
      ],
      "metadata": {
        "id": "Dzq3qiLS9-u8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Albumentations"
      ],
      "metadata": {
        "id": "Y7NgVvbE-AHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import albumentations as A\n",
        "  from albumentations.pytorch import ToTensorV2\n",
        "except:\n",
        "  print(\"[!] Couldn't find albumentations... installing it.\")\n",
        "  !pip install -U albumentations\n",
        "  import albumentations as A\n",
        "  from albumentations.pytorch import ToTensorV2"
      ],
      "metadata": {
        "id": "NOCIrRda-BYM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Definitions"
      ],
      "metadata": {
        "id": "k7-nIydz-Fp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder Utilities ----------------------------\n",
        "\n",
        "## Create dir if it doesn't exist\n",
        "def create_dir(dir_name):\n",
        "  if not os.path.exists(f'/content/{dir_name}'):\n",
        "    os.mkdir(f'/content/{dir_name}')\n",
        "\n",
        "## Delete dir: checkpoints\n",
        "def delete_dir(dir_name):\n",
        "  if os.path.isdir(f'/content/{dir_name}'):\n",
        "    shutil.rmtree(f'/content/{dir_name}')\n",
        "\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "B7a_Sbx5-Gyu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config File, Seeds & Devices"
      ],
      "metadata": {
        "id": "qigozplb-TDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Log this config file to wandb\n",
        "CONFIG = dict(\n",
        "    seed=42,\n",
        "    DATA_ROOT = '/content/',\n",
        "    BATCH_SIZE = 64,\n",
        "    WORKERS = 2,\n",
        "    IMG_SIZE = (28,28),\n",
        "    NUM_EPOCHS = 20,\n",
        "    nz=100,\n",
        "    lr = 0.00005,\n",
        "    nc = 1,  \n",
        "    disc_steps=5,\n",
        "    checkpoint_path='/content/checkpoints/',\n",
        "    clipping_c=0.01\n",
        "    )"
      ],
      "metadata": {
        "id": "uWjUuUh8-PQF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(CONFIG['seed'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2PolDP7SqEU",
        "outputId": "15267e2b-9ca3-4ab8-8159-dc54a819c9d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfi7e5KrSrsk",
        "outputId": "c513f252-76c1-449f-904b-511032bb08b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforms"
      ],
      "metadata": {
        "id": "Z0bspYGB851c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchvision.transforms as T\n",
        "# train_transform = A.Compose(\n",
        "#     [\n",
        "#         A.SmallestMaxSize(max_size=160),\n",
        "#         A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
        "#         A.RandomCrop(height=128, width=128),\n",
        "#         A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
        "#         A.RandomBrightnessContrast(p=0.5),\n",
        "#         A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "#         ToTensorV2(),\n",
        "#     ]\n",
        "# )\n",
        "train_transform = Compose([\n",
        "    # T.RandomAffine(degrees=15, translate=(0.1,0.1), scale=(0.8,1.2)),\n",
        "    # T.RandomHorizontalFlip(p=0.5),\n",
        "    T.GaussianBlur(kernel_size=3),\n",
        "    ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "zvbPlyvZ89rF"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset & DataLoaders (use lightning's Data Module class this time)"
      ],
      "metadata": {
        "id": "QXCjhCis8-Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torchvision.datasets.FashionMNIST(root=\"train_data\", \n",
        "                                               train = True, \n",
        "                                               transform = train_transform, \n",
        "                                               target_transform = None, \n",
        "                                               download = True)"
      ],
      "metadata": {
        "id": "fyutMQiH-U8U"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = torchvision.datasets.FashionMNIST(root=\"test_data\",\n",
        "                                              train=False, \n",
        "                                              transform=Compose([ToTensor()]), \n",
        "                                              target_transform=None, \n",
        "                                              download=True)"
      ],
      "metadata": {
        "id": "y-sbDzg1ox7K"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_data), len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-rOZjAmEZJf",
        "outputId": "e4c1dd0a-f5e0-423a-9fec-21c9f5098b3a"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=CONFIG['BATCH_SIZE'], shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=CONFIG['BATCH_SIZE'], shuffle=True)"
      ],
      "metadata": {
        "id": "w4taEkO_EoEg"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity Visualizations"
      ],
      "metadata": {
        "id": "8IdfCGJn9EYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "    img, label = train_data[sample_idx]\n",
        "    # print(img.shape)\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "qP4uDops9Grt",
        "outputId": "2868548a-af8c-4d29-d782-83a9b95006aa"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Arch"
      ],
      "metadata": {
        "id": "8xEbBzpU9Hil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "eagh9GG-SbwA"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator\n",
        "\n",
        "> No Sigmoid at the end!   \n",
        "> Values can range from -∞ to ∞"
      ],
      "metadata": {
        "id": "H7c8Yqcc9MYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_shape):\n",
        "    super().__init__()\n",
        "\n",
        "    self.img_shape = img_shape\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(int(np.prod(self.img_shape)), 512),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(inplace=True),   \n",
        "        nn.Linear(128,1)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = x.view(x.size(0), -1)\n",
        "    real_or_fake = self.model(x)\n",
        "    return real_or_fake"
      ],
      "metadata": {
        "id": "IrSce6u_9LNM"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = Discriminator(img_shape=CONFIG['IMG_SIZE']).to(device)\n",
        "summary(d, (1,28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtkrA-fbSgLM",
        "outputId": "a85e010e-81d0-4a4d-87b6-20cd14dca754"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 512]         401,920\n",
            "              ReLU-2                  [-1, 512]               0\n",
            "            Linear-3                  [-1, 256]         131,328\n",
            "              ReLU-4                  [-1, 256]               0\n",
            "            Linear-5                  [-1, 128]          32,896\n",
            "              ReLU-6                  [-1, 128]               0\n",
            "            Linear-7                    [-1, 1]             129\n",
            "================================================================\n",
            "Total params: 566,273\n",
            "Trainable params: 566,273\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 2.16\n",
            "Estimated Total Size (MB): 2.18\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator"
      ],
      "metadata": {
        "id": "a7Gx1Evy9OJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, img_shape, latent_dim: int = 100):\n",
        "    super().__init__()\n",
        "\n",
        "    self.img_shape = img_shape\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(latent_dim, 128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(128, 256),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(256, 512),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(512, 784),\n",
        "        nn.Sigmoid()          \n",
        "    )\n",
        "  \n",
        "  def forward(self, z):\n",
        "    img = self.model(z)\n",
        "    img = img.view(img.size(0), *self.img_shape)\n",
        "    return img"
      ],
      "metadata": {
        "id": "qpX_I4qB9PJt"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = Generator(CONFIG['IMG_SIZE']).to(device)\n",
        "summary(g, (100, 1, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsoJaO9zSeAz",
        "outputId": "9150b0a1-f5cc-4494-852e-5980cc192c3a"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 100]               0\n",
            "            Linear-2                  [-1, 128]          12,928\n",
            "              ReLU-3                  [-1, 128]               0\n",
            "            Linear-4                  [-1, 256]          33,024\n",
            "              ReLU-5                  [-1, 256]               0\n",
            "            Linear-6                  [-1, 512]         131,584\n",
            "              ReLU-7                  [-1, 512]               0\n",
            "            Linear-8                  [-1, 784]         402,192\n",
            "           Sigmoid-9                  [-1, 784]               0\n",
            "================================================================\n",
            "Total params: 579,728\n",
            "Trainable params: 579,728\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.03\n",
            "Params size (MB): 2.21\n",
            "Estimated Total Size (MB): 2.24\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FID"
      ],
      "metadata": {
        "id": "HiqSa8B6oxo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionV3(nn.Module):\n",
        "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
        "\n",
        "    # Index of default block of inception to return,\n",
        "    # corresponds to output of final average pooling\n",
        "    DEFAULT_BLOCK_INDEX = 3\n",
        "\n",
        "    # Maps feature dimensionality to their output blocks indices\n",
        "    BLOCK_INDEX_BY_DIM = {\n",
        "        64: 0,   # First max pooling features\n",
        "        192: 1,  # Second max pooling featurs\n",
        "        768: 2,  # Pre-aux classifier features\n",
        "        2048: 3  # Final average pooling features\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 output_blocks=[DEFAULT_BLOCK_INDEX],\n",
        "                 resize_input=True,\n",
        "                 normalize_input=True,\n",
        "                 requires_grad=False):\n",
        "        \n",
        "        super(InceptionV3, self).__init__()\n",
        "\n",
        "        self.resize_input = resize_input\n",
        "        self.normalize_input = normalize_input\n",
        "        self.output_blocks = sorted(output_blocks)\n",
        "        self.last_needed_block = max(output_blocks)\n",
        "\n",
        "        assert self.last_needed_block <= 3, \\\n",
        "            'Last possible output block index is 3'\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "\n",
        "        \n",
        "        inception = torchvision.models.inception_v3(pretrained=True)\n",
        "\n",
        "        # Block 0: input to maxpool1\n",
        "        block0 = [\n",
        "            inception.Conv2d_1a_3x3,\n",
        "            inception.Conv2d_2a_3x3,\n",
        "            inception.Conv2d_2b_3x3,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        ]\n",
        "        self.blocks.append(nn.Sequential(*block0))\n",
        "\n",
        "        # Block 1: maxpool1 to maxpool2\n",
        "        if self.last_needed_block >= 1:\n",
        "            block1 = [\n",
        "                inception.Conv2d_3b_1x1,\n",
        "                inception.Conv2d_4a_3x3,\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block1))\n",
        "\n",
        "        # Block 2: maxpool2 to aux classifier\n",
        "        if self.last_needed_block >= 2:\n",
        "            block2 = [\n",
        "                inception.Mixed_5b,\n",
        "                inception.Mixed_5c,\n",
        "                inception.Mixed_5d,\n",
        "                inception.Mixed_6a,\n",
        "                inception.Mixed_6b,\n",
        "                inception.Mixed_6c,\n",
        "                inception.Mixed_6d,\n",
        "                inception.Mixed_6e,\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block2))\n",
        "\n",
        "        # Block 3: aux classifier to final avgpool\n",
        "        if self.last_needed_block >= 3:\n",
        "            block3 = [\n",
        "                inception.Mixed_7a,\n",
        "                inception.Mixed_7b,\n",
        "                inception.Mixed_7c,\n",
        "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block3))\n",
        "\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = requires_grad\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \"\"\"Get Inception feature maps\n",
        "        Parameters\n",
        "        ----------\n",
        "        inp : torch.autograd.Variable\n",
        "            Input tensor of shape Bx3xHxW. Values are expected to be in\n",
        "            range (0, 1)\n",
        "        Returns\n",
        "        -------\n",
        "        List of torch.autograd.Variable, corresponding to the selected output\n",
        "        block, sorted ascending by index\n",
        "        \"\"\"\n",
        "        outp = []\n",
        "        if inp.shape[1] == 1:\n",
        "          inp = inp.expand(inp.shape[0], 3, *inp.shape[2:])\n",
        "          print(inp.shape)\n",
        "        x = inp\n",
        "\n",
        "        if self.resize_input:\n",
        "            x = F.interpolate(x,\n",
        "                              size=(299, 299),\n",
        "                              mode='bilinear',\n",
        "                              align_corners=False)\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
        "\n",
        "        for idx, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            if idx in self.output_blocks:\n",
        "                outp.append(x)\n",
        "\n",
        "            if idx == self.last_needed_block:\n",
        "                break\n",
        "\n",
        "        return outp\n",
        "    \n",
        "    \n",
        "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
        "model_inc = InceptionV3([block_idx])\n",
        "model_inc = model_inc.cuda()\n",
        "\n",
        "\n",
        "def calculate_activation_statistics(images,model,batch_size=128, dims=2048,\n",
        "                    cuda=False):\n",
        "    model.eval()\n",
        "    act=np.empty((len(images), dims))\n",
        "    \n",
        "    if cuda:\n",
        "        batch=images.cuda()\n",
        "    else:\n",
        "        batch=images\n",
        "    pred = model(batch)[0]\n",
        "\n",
        "        # If model output is not scalar, apply global spatial average pooling.\n",
        "        # This happens if you choose a dimensionality not equal 2048.\n",
        "    if pred.size(2) != 1 or pred.size(3) != 1:\n",
        "        pred = nn.functional.adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
        "\n",
        "    act= pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
        "    \n",
        "    mu = np.mean(act, axis=0)\n",
        "    sigma = np.cov(act, rowvar=False)\n",
        "    return mu, sigma\n",
        "\n",
        "\n",
        "from scipy.linalg import sqrtm\n",
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "    \"\"\"\n",
        "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
        "    and X_2 ~ N(mu_2, C_2) is:\n",
        "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2))\n",
        "    \"\"\"\n",
        "\n",
        "    mu1 = np.atleast_1d(mu1)\n",
        "    mu2 = np.atleast_1d(mu2)\n",
        "\n",
        "    sigma1 = np.atleast_2d(sigma1)\n",
        "    sigma2 = np.atleast_2d(sigma2)\n",
        "\n",
        "    assert mu1.shape == mu2.shape, \\\n",
        "        'Training and test mean vectors have different lengths'\n",
        "    assert sigma1.shape == sigma2.shape, \\\n",
        "        'Training and test covariances have different dimensions'\n",
        "\n",
        "    diff = mu1 - mu2\n",
        "    \n",
        "    covmean, _ = sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if not np.isfinite(covmean).all():\n",
        "        msg = ('fid calculation produces singular product; '\n",
        "               'adding %s to diagonal of cov estimates') % eps\n",
        "        print(msg)\n",
        "        offset = np.eye(sigma1.shape[0]) * eps\n",
        "        covmean = np.linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "\n",
        "    \n",
        "    if np.iscomplexobj(covmean):\n",
        "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "            m = np.max(np.abs(covmean.imag))\n",
        "            raise ValueError('Imaginary component {}'.format(m))\n",
        "        covmean = covmean.real\n",
        "\n",
        "    tr_covmean = np.trace(covmean)\n",
        "\n",
        "    return (diff.dot(diff) + np.trace(sigma1) +\n",
        "            np.trace(sigma2) - 2 * tr_covmean)\n",
        "\n",
        "\n",
        "def calculate_fretchet(images_real,images_fake,model):\n",
        "     mu_1,std_1=calculate_activation_statistics(images_real,model,cuda=True)\n",
        "     mu_2,std_2=calculate_activation_statistics(images_fake,model,cuda=True)\n",
        "    \n",
        "     \"\"\"get fretched distance\"\"\"\n",
        "     fid_value = calculate_frechet_distance(mu_1, std_1, mu_2, std_2)\n",
        "     return fid_value"
      ],
      "metadata": {
        "id": "SV6Nq_iOoyw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39ab81e-019a-4f88-b6dd-4d72cbbd06f8"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lightning Recipe"
      ],
      "metadata": {
        "id": "2JiMBjrMJaFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LIT_WGAN(pl.LightningModule):\n",
        "  \n",
        "  def __init__(self, \n",
        "               discriminator_model, \n",
        "               generator_model, \n",
        "               latent_dim: int = 100, \n",
        "               lr: float = 0.003, \n",
        "               clipping_c: float = 0.01,\n",
        "               disc_steps: int = 5,\n",
        "               isGP=False):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.save_hyperparameters(ignore=[discriminator_model, generator_model])\n",
        "    self.automatic_optimization = False\n",
        "\n",
        "    self.discriminator = discriminator_model\n",
        "    self.generator = generator_model\n",
        "    self.weight_cliping_limit = clipping_c\n",
        "\n",
        "    self.isGP = isGP\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    lr = self.hparams.lr\n",
        "\n",
        "    optim_g = torch.optim.RMSprop(self.generator.parameters(), lr=lr)\n",
        "    optim_d = torch.optim.RMSprop(self.discriminator.parameters(), lr=lr)\n",
        "\n",
        "    return [optim_g, optim_d], []\n",
        "\n",
        "  def compute_gradient_penalty(self, real_samples, fake_samples):\n",
        "    # Random weight term for interpolation between real and fake samples\n",
        "    alpha = torch.Tensor(np.random.random((real_samples.size(0), 1, 1, 1))).to(self.device)\n",
        "\n",
        "    # Get random interpolation between real and fake samples\n",
        "    # print((torch.sub(alpha, 1) * fake_samples).shape)\n",
        "    interpolates = (alpha * real_samples + (torch.sub(alpha,1) * fake_samples)).requires_grad_(True)\n",
        "    interpolates = interpolates.to(self.device)\n",
        "    # print(\"interpolates.shape:\",interpolates.shape)\n",
        "    d_interpolates = self.discriminator(interpolates)\n",
        "    # print(\"d_interpolates.shape:\", d_interpolates.shape)\n",
        "    fake = torch.Tensor(real_samples.shape[0], 1).fill_(1.0).to(self.device)\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1).to(self.device)\n",
        "    # print(\"gradients.shape:\", gradients.shape)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty\n",
        "\n",
        "  def forward(self, z):\n",
        "    return self.generator(z)\n",
        " \n",
        "\n",
        "  def test_step(self, batch, batch_idx): # Use for Exploring the latent space \n",
        "    imgs, _ = batch\n",
        "    pass\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    imgs, _ = batch\n",
        "\n",
        "    imgs = imgs.to(device)\n",
        "\n",
        "    z = torch.randn(imgs.shape[0], self.hparams.latent_dim, 1, 1) # N x Z_d x 1 x 1\n",
        "    z = z.type_as(imgs).to(device)\n",
        "\n",
        "    fake_imgs = self.generator(z)\n",
        "    g_loss = -1.0 * self.discriminator(fake_imgs).mean(0)\n",
        "\n",
        "    d_loss_real = -1.0 * self.discriminator(imgs).mean(0) # move towards -inf\n",
        "    d_loss_fake = self.discriminator(self.generator(z)).mean(0) # move towards -inf\n",
        "    \n",
        "    gp_term = 10. * self.compute_gradient_penalty(imgs, fake_imgs)\n",
        "    if self.isGP:\n",
        "      d_loss = gp_term\n",
        "    else:\n",
        "      d_loss = 0\n",
        "\n",
        "    d_loss += (d_loss_fake + d_loss_real) / 2.\n",
        "\n",
        "    print(fake_imgs.shape)\n",
        "    fid = calculate_fretchet(imgs, fake_imgs, model_inc)\n",
        "\n",
        "    self.log_dict({\"val_g_loss\": g_loss, \"val_d_loss\": d_loss, \"FID\": fid}, \n",
        "                  on_step=True, \n",
        "                  on_epoch=True, \n",
        "                  prog_bar=True, \n",
        "                  logger=True)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    imgs, _ = batch\n",
        "    # print(f\"{batch_idx}:: imgs.shape =\",imgs.shape)\n",
        "    opt_g, opt_d = self.optimizers()\n",
        "\n",
        "    z = torch.randn(imgs.shape[0], self.hparams.latent_dim, 1, 1) # N x Z_d x 1 x 1\n",
        "    z = z.type_as(imgs)\n",
        "\n",
        "    # print(f\"Disc out shape:\", self.discriminator(self(z)).shape)\n",
        "\n",
        "    # Train G:\n",
        "    self.toggle_optimizer(opt_g)\n",
        "    \n",
        "    # Generator loss:\n",
        "    fake_imgs = self.generator(z)\n",
        "    # print(f\"Gen out: {fake_imgs.shape}\")\n",
        "    # print(f\"Disc out: {self.discriminator(fake_imgs).mean(0).shape}\")\n",
        "    g_loss = -1.0 * self.discriminator(fake_imgs).mean(0) # minus to minimize g_loss:: ideal out per example: -inf\n",
        "\n",
        "    # Grad step:\n",
        "    self.manual_backward(g_loss)\n",
        "    opt_g.step()\n",
        "    opt_g.zero_grad()\n",
        "\n",
        "        \n",
        "    self.untoggle_optimizer(opt_g)\n",
        "\n",
        "    # Train Discriminator\n",
        "    self.toggle_optimizer(opt_d)\n",
        "\n",
        "    for i in range(self.hparams.disc_steps): # 5 (from WGAN paper)\n",
        "      # Discriminator loss:\n",
        "      d_loss_real = -1.0 * self.discriminator(imgs).mean(0).item() # move towards -inf\n",
        "      d_loss_fake = self.discriminator(self.generator(z)).mean(0).item() # move towards -inf\n",
        "\n",
        "      # Lambda_gp = 10.0\n",
        "      gp_term = 10. * self.compute_gradient_penalty(imgs, self.generator(z)[:, None, :, :])\n",
        "      if self.isGP:\n",
        "        d_loss = gp_term\n",
        "      else:\n",
        "        d_loss = 0\n",
        "\n",
        "      d_loss += (d_loss_fake + d_loss_real) / 2.\n",
        "\n",
        "      # self.log(\"d_loss\", d_loss, prog_bar=True)\n",
        "      self.manual_backward(d_loss)\n",
        "      opt_d.step()\n",
        "\n",
        "      if not self.isGP:\n",
        "        for weight in self.discriminator.parameters():\n",
        "          weight.data.clamp_(-self.weight_cliping_limit, self.weight_cliping_limit)\n",
        "\n",
        "      opt_d.zero_grad()\n",
        "    \n",
        "\n",
        "    self.untoggle_optimizer(opt_d)\n",
        "    # print(fake_imgs[0].shape)\n",
        "    \n",
        "    self.logger.experiment.log({\"Gen_Image_1 (during training)\":[wandb.Image(fake_imgs[0].cpu(), caption=\"Gen Out\")]})\n",
        "\n",
        "    self.log_dict({\"g_loss\": g_loss, \"d_loss\": d_loss}, \n",
        "                  on_step=True, \n",
        "                  on_epoch=True, \n",
        "                  prog_bar=True, \n",
        "                  logger=True)\n"
      ],
      "metadata": {
        "id": "qoZf73jnJb02"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wgan = LIT_WGAN(\n",
        "      discriminator_model = Discriminator(CONFIG['IMG_SIZE']), \n",
        "      generator_model = Generator(CONFIG['IMG_SIZE']), \n",
        "      latent_dim = CONFIG['nz'],\n",
        "      lr=CONFIG['lr'],\n",
        "      clipping_c = CONFIG['clipping_c'],\n",
        "      disc_steps=CONFIG['disc_steps'],\n",
        "      isGP=True\n",
        "    )\n",
        "\n",
        "summary = ModelSummary(wgan, max_depth=-1)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4MdtV6pS5Q7",
        "outputId": "2fdc6fe3-071b-4614-e4b6-5a6893d40756"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   | Name                  | Type          | Params\n",
            "---------------------------------------------------------\n",
            "0  | discriminator         | Discriminator | 566 K \n",
            "1  | discriminator.model   | Sequential    | 566 K \n",
            "2  | discriminator.model.0 | Linear        | 401 K \n",
            "3  | discriminator.model.1 | ReLU          | 0     \n",
            "4  | discriminator.model.2 | Linear        | 131 K \n",
            "5  | discriminator.model.3 | ReLU          | 0     \n",
            "6  | discriminator.model.4 | Linear        | 32.9 K\n",
            "7  | discriminator.model.5 | ReLU          | 0     \n",
            "8  | discriminator.model.6 | Linear        | 129   \n",
            "9  | generator             | Generator     | 579 K \n",
            "10 | generator.model       | Sequential    | 579 K \n",
            "11 | generator.model.0     | Flatten       | 0     \n",
            "12 | generator.model.1     | Linear        | 12.9 K\n",
            "13 | generator.model.2     | ReLU          | 0     \n",
            "14 | generator.model.3     | Linear        | 33.0 K\n",
            "15 | generator.model.4     | ReLU          | 0     \n",
            "16 | generator.model.5     | Linear        | 131 K \n",
            "17 | generator.model.6     | ReLU          | 0     \n",
            "18 | generator.model.7     | Linear        | 402 K \n",
            "19 | generator.model.8     | Sigmoid       | 0     \n",
            "---------------------------------------------------------\n",
            "1.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.1 M     Total params\n",
            "4.584     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'discriminator_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['discriminator_model'])`.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'generator_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['generator_model'])`.\n",
            "  rank_zero_warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logger: Proj, Run ... Names"
      ],
      "metadata": {
        "id": "UBs1k1UcTEHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb_logger = WandbLogger(project='M2-WGAN', \n",
        "                           name='exp-gp-2_blur',\n",
        "                           config=CONFIG,\n",
        "                           job_type='train',\n",
        "                           log_model=\"all\")\n",
        "\n",
        "# wandb_logger = WandbLogger(project='M2-WGAN', \n",
        "#                            name='exp-gp-3_flip_and_blur',\n",
        "#                            config=CONFIG,\n",
        "#                            job_type='train',\n",
        "#                            log_model=\"all\")\n",
        "\n",
        "# wandb_logger = WandbLogger(project='M2-WGAN', \n",
        "#                            name='exp-gp-4_all_augs',\n",
        "#                            config=CONFIG,\n",
        "#                            job_type='train',\n",
        "#                            log_model=\"all\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "kcyCL6snTG7T",
        "outputId": "06151bd9-32d0-40db-cef2-bf92daab104e"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20230521_060102-es2amq9k</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aryangarg019/M2-WGAN/runs/es2amq9k' target=\"_blank\">exp-gp-1_no_augs</a></strong> to <a href='https://wandb.ai/aryangarg019/M2-WGAN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aryangarg019/M2-WGAN' target=\"_blank\">https://wandb.ai/aryangarg019/M2-WGAN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aryangarg019/M2-WGAN/runs/es2amq9k' target=\"_blank\">https://wandb.ai/aryangarg019/M2-WGAN/runs/es2amq9k</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer Callbacks"
      ],
      "metadata": {
        "id": "mt04CG7LTA7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Callback\n",
        "from lightning.pytorch.callbacks import DeviceStatsMonitor, TQDMProgressBar, ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
        "\n",
        "# Checkpoint\n",
        "checkpoint_callback = ModelCheckpoint(dirpath=CONFIG['checkpoint_path'],\n",
        "                                      filename='{epoch}-{g_loss:.3f}',\n",
        "                                      monitor='g_loss',\n",
        "                                      save_top_k=-1,\n",
        "                                      save_last=True,\n",
        "                                      save_weights_only=True,\n",
        "                                      verbose=True,\n",
        "                                      mode='min')\n",
        "\n",
        "# Exp2: Learning Rate Monitor\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step', log_momentum=False)\n",
        "\n",
        "# Earlystopping\n",
        "# earlystopping = EarlyStopping(monitor='val_d_acc', patience=3, mode='min')"
      ],
      "metadata": {
        "id": "IMhsymGETCPd"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer"
      ],
      "metadata": {
        "id": "PafBi2NoTPh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(fast_dev_run=False,    # For debugging purposes\n",
        "                     log_every_n_steps=1,   # set the logging frequency\n",
        "                     accelerator='auto',    # Precedence: tpu > gpu >> cpu\n",
        "                     devices=\"auto\",        # all\n",
        "                     max_epochs= 5,         # CONFIG['NUM_EPOCHS'],\n",
        "                     callbacks=[TQDMProgressBar(refresh_rate=25), \n",
        "                                checkpoint_callback, \n",
        "                                lr_monitor],\n",
        "                     logger=wandb_logger,    # wandb <3\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPteL0AuTO7p",
        "outputId": "4c5141d4-c2ba-45fd-823c-2ee3a48713ad"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "lL4nBV6eTXua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(wgan, train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565,
          "referenced_widgets": [
            "8c791224974d4e7b85ac173c77c38f07",
            "d7656f9728404a429d37f00e6b086daa",
            "6c7b493e5017482db645b1be07f9b067",
            "c03a63f1287a43b3913cd5d575a81b88",
            "a3e54ca7a5f040ec9d9b1d6279b23eca",
            "854ea0ab6cca4be6954fdb708dc72d31",
            "3a7e361a16e64bcab2feba934b65598e",
            "e68cf24c149c4312bb3182129fa193d8",
            "5f3754ac6afb45d395bbb1ffb7fcb10d",
            "4f5dfc0839144c1bb12fa1ae937b37b1",
            "a314f70cf9eb438fb82486b1f6ec32d4"
          ]
        },
        "id": "K1_kqDmpTSGC",
        "outputId": "ee144623-dc4f-4a29-d1ea-04683fe63965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /content/checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type          | Params\n",
            "------------------------------------------------\n",
            "0 | discriminator | Discriminator | 566 K \n",
            "1 | generator     | Generator     | 579 K \n",
            "------------------------------------------------\n",
            "1.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.1 M     Total params\n",
            "4.584     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type          | Params\n",
            "------------------------------------------------\n",
            "0 | discriminator | Discriminator | 566 K \n",
            "1 | generator     | Generator     | 579 K \n",
            "------------------------------------------------\n",
            "1.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.1 M     Total params\n",
            "4.584     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c791224974d4e7b85ac173c77c38f07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Epoch 0, global step 5628: 'g_loss' reached -6.57098 (best -6.57098), saving model to '/content/checkpoints/epoch=0-g_loss=-6.571.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 5628: 'g_loss' reached -6.57098 (best -6.57098), saving model to '/content/checkpoints/epoch=0-g_loss=-6.571.ckpt' as top 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Call Finish on Exp logger"
      ],
      "metadata": {
        "id": "aEHG4cjBgIMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "9_3-dK_FgF2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqiT4jWm4Fyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}