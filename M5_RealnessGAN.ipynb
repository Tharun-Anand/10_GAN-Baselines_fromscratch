{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJnqDELD8t1x"
      },
      "source": [
        "# RealnessGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKl81qZA8yvl"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNGGKEk680T9"
      },
      "source": [
        "### wandb (interactive cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL25Wf7N7U3d",
        "outputId": "ebd9cc91-386b-41f8-daf0-6a19e686142d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maryangarg019\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip -qqq install wandb pytorch-lightning torchmetrics\n",
        "\n",
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "wandb.login()\n",
        "\n",
        "# API Key:\n",
        "# d926baa25b6a14ffa4e5c30a6f3bbffbeca8fcf1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fYiQ8KT93mk"
      },
      "source": [
        "### Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l72VnqKx946V"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import lightning.pytorch as pl\n",
        "except:\n",
        "  print(\"[!] Couldn't find pytorch-lightning.\\nInstalling it...\\n\")\n",
        "  !pip install lightning\n",
        "  import lightning.pytorch as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2f6GKjlv97Hk"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.utilities.model_summary import ModelSummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aW1Wbm2298Km"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import seed_everything"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1EQePfV83O2"
      },
      "source": [
        "### standard imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6AevVvdl85Um"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dzq3qiLS9-u8"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torchvision.utils import make_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7NgVvbE-AHU"
      },
      "source": [
        "### Albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NOCIrRda-BYM"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import albumentations as A\n",
        "  from albumentations.pytorch import ToTensorV2\n",
        "except:\n",
        "  print(\"[!] Couldn't find albumentations... installing it.\")\n",
        "  !pip install -U albumentations > /dev/null\n",
        "  import albumentations as A\n",
        "  from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuT0EsLu-CxA"
      },
      "source": [
        "### Torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cwd6G-Tk-D2l"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import torchmetrics\n",
        "except:\n",
        "  print(f\"[!] Torchmetrics couldn't be imported.\\nInstalling...\")\n",
        "  !pip install torchmetrics > /dev/null\n",
        "  import torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7-nIydz-Fp8"
      },
      "source": [
        "### Custom Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B7a_Sbx5-Gyu"
      },
      "outputs": [],
      "source": [
        "# Folder Utilities ----------------------------\n",
        "\n",
        "## Create dir if it doesn't exist\n",
        "def create_dir(dir_name):\n",
        "  if not os.path.exists(f'/content/{dir_name}'):\n",
        "    os.mkdir(f'/content/{dir_name}')\n",
        "\n",
        "## Delete dir: checkpoints\n",
        "def delete_dir(dir_name):\n",
        "  if os.path.isdir(f'/content/{dir_name}'):\n",
        "    shutil.rmtree(f'/content/{dir_name}')\n",
        "\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qigozplb-TDs"
      },
      "source": [
        "## Config File, Seeds & Devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uWjUuUh8-PQF"
      },
      "outputs": [],
      "source": [
        "# Log this config file to wandb\n",
        "CONFIG = dict(\n",
        "    seed=42,\n",
        "    DATA_ROOT = '/content/',\n",
        "    checkpoint_path='/content/checkpoints/',\n",
        "    G_LOSS_MODE = \"EQ19_V2\",\n",
        "    SAVE_FOLDER = \"resultsRealnessGAN\",\n",
        "    NUM_EPOCHS = 40,\n",
        "    BATCH_SIZE = 64,\n",
        "    D_LR = 2e-4,\n",
        "    G_LR = 2e-4,\n",
        "    BETA_1 = 0.5,\n",
        "    BETA_2 = 0.999,\n",
        "\n",
        "    # Model Hyperparameters\n",
        "    LATENT_DIM = 20,\n",
        "    HIDDEN_DIM = 256,\n",
        "    IMAGE_DIM = 784,\n",
        "    NUM_OUTCOMES = 10\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2PolDP7SqEU",
        "outputId": "2be8daa5-a68f-47ce-d0e3-b5fbea48a521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "seed_everything(CONFIG['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfi7e5KrSrsk",
        "outputId": "079acd6b-b216-4154-bcad-06069d0aae4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0bspYGB851c"
      },
      "source": [
        "## Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zvbPlyvZ89rF"
      },
      "outputs": [],
      "source": [
        "# train_transform = A.Compose(\n",
        "#     [\n",
        "#         A.SmallestMaxSize(max_size=160),\n",
        "#         A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
        "#         A.RandomCrop(height=128, width=128),\n",
        "#         A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
        "#         A.RandomBrightnessContrast(p=0.5),\n",
        "#         A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "#         ToTensorV2(),\n",
        "#     ]\n",
        "# )\n",
        "van_transform = T.Compose([T.ToTensor()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXCjhCis8-Ft"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST('data', train=True, transform=van_transform, download=True)"
      ],
      "metadata": {
        "id": "ZfnZWsRtcxP0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E99F5Uyd_0r4"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True)"
      ],
      "metadata": {
        "id": "dpl7qInhc2wy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some More Settings"
      ],
      "metadata": {
        "id": "za45SWuDY26O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Settings\n",
        "NUM_EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "D_LR = 2e-4\n",
        "G_LR = 2e-4\n",
        "LR = G_LR\n",
        "\n",
        "# Model Hyperparameters\n",
        "LATENT_DIM = 20\n",
        "HIDDEN_DIM = 256\n",
        "IMAGE_DIM = 784\n",
        "NUM_OUTCOMES = 10"
      ],
      "metadata": {
        "id": "ZD-4IdjAY2BO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xEbBzpU9Hil"
      },
      "source": [
        "## Model Arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eagh9GG-SbwA"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7c8Yqcc9MYN"
      },
      "source": [
        "### Discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IrSce6u_9LNM"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_outcomes):\n",
        "\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.02),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.02),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.02),\n",
        "\n",
        "            nn.Linear(hidden_dim, num_outcomes),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtkrA-fbSgLM",
        "outputId": "3b2b4e95-82d5-42cd-bbd7-7ab8a2c39da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 256]         200,960\n",
            "         LeakyReLU-2               [-1, 1, 256]               0\n",
            "            Linear-3               [-1, 1, 256]          65,792\n",
            "         LeakyReLU-4               [-1, 1, 256]               0\n",
            "            Linear-5               [-1, 1, 256]          65,792\n",
            "         LeakyReLU-6               [-1, 1, 256]               0\n",
            "            Linear-7                [-1, 1, 10]           2,570\n",
            "           Softmax-8                [-1, 1, 10]               0\n",
            "================================================================\n",
            "Total params: 335,114\n",
            "Trainable params: 335,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.28\n",
            "Estimated Total Size (MB): 1.29\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "d = Discriminator(IMAGE_DIM, HIDDEN_DIM, NUM_OUTCOMES).to(device)\n",
        "summary(d, (1,784))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Gx1Evy9OJH"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qpX_I4qB9PJt"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, out_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(hidden_dim, out_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsoJaO9zSeAz",
        "outputId": "751f1c8b-93ec-4f9d-fb69-b9f584130ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                   [-1, 20]               0\n",
            "            Linear-2                  [-1, 256]           5,376\n",
            "       BatchNorm1d-3                  [-1, 256]             512\n",
            "              ReLU-4                  [-1, 256]               0\n",
            "            Linear-5                  [-1, 256]          65,792\n",
            "       BatchNorm1d-6                  [-1, 256]             512\n",
            "              ReLU-7                  [-1, 256]               0\n",
            "            Linear-8                  [-1, 256]          65,792\n",
            "       BatchNorm1d-9                  [-1, 256]             512\n",
            "             ReLU-10                  [-1, 256]               0\n",
            "           Linear-11                  [-1, 256]          65,792\n",
            "      BatchNorm1d-12                  [-1, 256]             512\n",
            "             ReLU-13                  [-1, 256]               0\n",
            "           Linear-14                  [-1, 784]         201,488\n",
            "             Tanh-15                  [-1, 784]               0\n",
            "================================================================\n",
            "Total params: 406,288\n",
            "Trainable params: 406,288\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 1.55\n",
            "Estimated Total Size (MB): 1.59\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "g = Generator(LATENT_DIM, HIDDEN_DIM, IMAGE_DIM).to(device)\n",
        "summary(g, (1,LATENT_DIM))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities-2\n",
        "\n"
      ],
      "metadata": {
        "id": "5PhvAf18dhCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def saveimg(image, savepath):\n",
        "  image = image.transpose(1,2,0)\n",
        "  plt.imsave(savepath, image)\n",
        "\n",
        "\n",
        "def scale(tensor, mini=-1, maxi=1):\n",
        "  return tensor * (maxi - mini) + mini\n",
        "\n",
        "\n",
        "def scale_back(tensor, mini=-1, maxi=1):\n",
        "  return (tensor-mini)/(maxi-mini)\n",
        "\n",
        "\n",
        "def generate_latent(batch_size, latent_dim):\n",
        "  return torch.empty(batch_size, latent_dim).uniform_(-1,1).to(device)\n",
        "\n",
        "\n",
        "fixed_z = generate_latent(64, LATENT_DIM)\n",
        "# print(fixed_z.shape)"
      ],
      "metadata": {
        "id": "Mmd1GYtPdda2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JiMBjrMJaFM"
      },
      "source": [
        "## Lightning Recipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skewnorm"
      ],
      "metadata": {
        "id": "ZcLclM6-eV8D"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qoZf73jnJb02"
      },
      "outputs": [],
      "source": [
        "class LIT_realnessGAN(pl.LightningModule):\n",
        "  \n",
        "  def __init__(self, \n",
        "               discriminator_model, \n",
        "               generator_model, \n",
        "               lr: float = 0.003,\n",
        "               b1: float = 0.5,\n",
        "               b2: float = 0.999, \n",
        "               disc_steps: int = 1):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.save_hyperparameters(ignore=[discriminator_model, \n",
        "                                      generator_model])\n",
        "    \n",
        "    self.automatic_optimization = False\n",
        "\n",
        "    self.d = discriminator_model\n",
        "    self.g = generator_model\n",
        "\n",
        "    # Anchor 0 = Skewed normal to the left\n",
        "    skew = skewnorm.rvs(-5, size=1000)\n",
        "    count, bins = np.histogram(skew, NUM_OUTCOMES)\n",
        "    anchor0 = count / sum(count)\n",
        "\n",
        "    # Anchor 1 = Skewed normal to the right\n",
        "    skew = skewnorm.rvs(5, size=1000)\n",
        "    count, bins = np.histogram(skew, NUM_OUTCOMES)\n",
        "    anchor1 = count / sum(count)\n",
        "\n",
        "    self.A0 = torch.from_numpy(np.array(anchor0)).to(device).float()\n",
        "    self.A1 = torch.from_numpy(np.array(anchor1)).to(device).float()\n",
        "\n",
        "    # Print KLD between the anchors\n",
        "    print(\"KLD(A0||A1): {}\".format(self.KLD(self.A0.view(1, -1), self.A1)))\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    lr = self.hparams.lr\n",
        "    b1 = self.hparams.b1\n",
        "    b2 = self.hparams.b2\n",
        "\n",
        "    optim_g = torch.optim.Adam(self.g.parameters(), lr=lr, betas=(b1,b2))\n",
        "    optim_d = torch.optim.Adam(self.d.parameters(), lr=lr, betas=(b1,b2))\n",
        "\n",
        "    return [optim_g, optim_d], []\n",
        "\n",
        "  def KLD(self, P, Q):\n",
        "    return torch.mean(torch.sum(P * (P/Q).log(), dim=1))\n",
        "\n",
        "  def forward(self, z):\n",
        "    return self.generator(z)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    real_images, _ = batch\n",
        "\n",
        "    batch_size = real_images.shape[0]\n",
        "\n",
        "    real_images = real_images.view(batch_size, -1).to(device)\n",
        "    real_images = scale(real_images, -1, 1)\n",
        "\n",
        "    optim_g, optim_d = self.optimizers()\n",
        "\n",
        "    self.toggle_optimizer(optim_d)\n",
        "\n",
        "    optim_d.zero_grad()\n",
        "\n",
        "    # Discriminator Real Loss\n",
        "    d_real_out = self.d(real_images)\n",
        "    d_real_loss = self.KLD(d_real_out, self.A1)\n",
        "    \n",
        "    # Discriminator Fake Loss\n",
        "    z = generate_latent(batch_size, LATENT_DIM)\n",
        "    fake_images = self.g(z)\n",
        "    d_fake_out = self.d(fake_images)\n",
        "    d_fake_loss = self.KLD(self.A0, d_fake_out)\n",
        "\n",
        "    # Total Discriminator Loss, Backprop, and Gradient Descent\n",
        "    d_loss = d_real_loss + d_fake_loss\n",
        "    d_loss = torch.autograd.Variable(d_loss, requires_grad = True)\n",
        "    self.manual_backward(d_loss)\n",
        "\n",
        "    optim_d.step()\n",
        "\n",
        "    self.untoggle_optimizer(optim_d)\n",
        "\n",
        "    self.toggle_optimizer(optim_g)\n",
        "    # Generator Forward Prop\n",
        "    optim_g.zero_grad()\n",
        "\n",
        "    z = generate_latent(batch_size, LATENT_DIM)\n",
        "    g_images = self.g(z)\n",
        "    d_g_out = self.d(g_images)\n",
        "\n",
        "    # Generator Loss\n",
        "    # Line 12 in Paper=> Use: G_LOSS_MODE = \"EQ19_V2\"\n",
        "    d_out = self.d(real_images)\n",
        "    g_loss = -1. * self.KLD(self.A0, d_g_out) + self.KLD(d_out, d_g_out)    # -KL(A0 || D(G(z))) + KL(D(x) || D(G(z)))\n",
        "    g_loss = torch.autograd.Variable(g_loss, requires_grad = True)\n",
        "    # Total Generator Loss, Backprop and Gradient Descent\n",
        "    self.manual_backward(g_loss)\n",
        "    optim_g.step()\n",
        "\n",
        "    # print(g_images.shape)\n",
        "    self.logger.experiment.log({\"Gen_Image (during training)\":[wandb.Image(torch.reshape(g_images[0], (28,28)).cpu(), \n",
        "                                                                           caption=\"RealnessG Out\")]})\n",
        "    self.log_dict({\"g_loss\": g_loss.item(), \"d_loss\": d_loss.item()}, \n",
        "                  on_step=True, \n",
        "                  on_epoch=True, \n",
        "                  prog_bar=True, \n",
        "                  logger=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "x4MdtV6pS5Q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03632e9c-4bcb-405e-9bec-686006784058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KLD(A0||A1): 2.6878838539123535\n",
            "   | Name       | Type          | Params\n",
            "----------------------------------------------\n",
            "0  | d          | Discriminator | 335 K \n",
            "1  | d.model    | Sequential    | 335 K \n",
            "2  | d.model.0  | Linear        | 200 K \n",
            "3  | d.model.1  | LeakyReLU     | 0     \n",
            "4  | d.model.2  | Linear        | 65.8 K\n",
            "5  | d.model.3  | LeakyReLU     | 0     \n",
            "6  | d.model.4  | Linear        | 65.8 K\n",
            "7  | d.model.5  | LeakyReLU     | 0     \n",
            "8  | d.model.6  | Linear        | 2.6 K \n",
            "9  | d.model.7  | Softmax       | 0     \n",
            "10 | g          | Generator     | 406 K \n",
            "11 | g.model    | Sequential    | 406 K \n",
            "12 | g.model.0  | Flatten       | 0     \n",
            "13 | g.model.1  | Linear        | 5.4 K \n",
            "14 | g.model.2  | BatchNorm1d   | 512   \n",
            "15 | g.model.3  | ReLU          | 0     \n",
            "16 | g.model.4  | Linear        | 65.8 K\n",
            "17 | g.model.5  | BatchNorm1d   | 512   \n",
            "18 | g.model.6  | ReLU          | 0     \n",
            "19 | g.model.7  | Linear        | 65.8 K\n",
            "20 | g.model.8  | BatchNorm1d   | 512   \n",
            "21 | g.model.9  | ReLU          | 0     \n",
            "22 | g.model.10 | Linear        | 65.8 K\n",
            "23 | g.model.11 | BatchNorm1d   | 512   \n",
            "24 | g.model.12 | ReLU          | 0     \n",
            "25 | g.model.13 | Linear        | 201 K \n",
            "26 | g.model.14 | Tanh          | 0     \n",
            "----------------------------------------------\n",
            "741 K     Trainable params\n",
            "0         Non-trainable params\n",
            "741 K     Total params\n",
            "2.966     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'discriminator_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['discriminator_model'])`.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'generator_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['generator_model'])`.\n",
            "  rank_zero_warn(\n"
          ]
        }
      ],
      "source": [
        "rgan = LIT_realnessGAN(\n",
        "      discriminator_model = Discriminator(IMAGE_DIM, HIDDEN_DIM, NUM_OUTCOMES),\n",
        "      generator_model = Generator(LATENT_DIM, HIDDEN_DIM, IMAGE_DIM),\n",
        "      lr=LR)\n",
        "\n",
        "summary = ModelSummary(rgan, max_depth=-1)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBs1k1UcTEHR"
      },
      "source": [
        "## Logger: Proj, Run ... Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kcyCL6snTG7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "85266ed0-b60f-47d1-add0-9b9465888286"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20230514_135608-24a4ngxp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aryangarg019/M5-RealnessGAN/runs/24a4ngxp' target=\"_blank\">exp-1_40eps</a></strong> to <a href='https://wandb.ai/aryangarg019/M5-RealnessGAN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/aryangarg019/M5-RealnessGAN' target=\"_blank\">https://wandb.ai/aryangarg019/M5-RealnessGAN</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/aryangarg019/M5-RealnessGAN/runs/24a4ngxp' target=\"_blank\">https://wandb.ai/aryangarg019/M5-RealnessGAN/runs/24a4ngxp</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb_logger = WandbLogger(project='M5-RealnessGAN', \n",
        "                           name='exp-1_40eps',\n",
        "                           config=CONFIG,\n",
        "                           job_type='train',\n",
        "                           log_model=\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt04CG7LTA7K"
      },
      "source": [
        "## Trainer Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IMhsymGETCPd"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import Callback\n",
        "from lightning.pytorch.callbacks import DeviceStatsMonitor, TQDMProgressBar, ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
        "\n",
        "# Checkpoint\n",
        "checkpoint_callback = ModelCheckpoint(dirpath=CONFIG['checkpoint_path'],\n",
        "                                      filename='{epoch}-{g_loss:.3f}',\n",
        "                                      monitor='g_loss',\n",
        "                                      save_top_k=-1,\n",
        "                                      save_last=True,\n",
        "                                      save_weights_only=True,\n",
        "                                      verbose=True,\n",
        "                                      mode='min')\n",
        "\n",
        "# Exp2: Learning Rate Monitor\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step', log_momentum=False)\n",
        "\n",
        "# Earlystopping\n",
        "# earlystopping = EarlyStopping(monitor='val_d_acc', patience=3, mode='min')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PafBi2NoTPh6"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPteL0AuTO7p",
        "outputId": "bfcc415b-d304-4567-8cb8-d874e8fd0cb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(fast_dev_run=False,    # For debugging purposes\n",
        "                     log_every_n_steps=1,   # set the logging frequency\n",
        "                     accelerator='auto',    # Precedence: tpu > gpu >> cpu\n",
        "                     devices=\"auto\",        # all\n",
        "                     max_epochs= NUM_EPOCHS,         # CONFIG['NUM_EPOCHS'],\n",
        "                     callbacks=[TQDMProgressBar(refresh_rate=25), \n",
        "                                checkpoint_callback, \n",
        "                                lr_monitor],\n",
        "                     logger=wandb_logger,    # wandb <3\n",
        "                     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL4nBV6eTXua"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520,
          "referenced_widgets": [
            "7bb32e5ae18948b8887d3eb5b411029d",
            "ea5842f0171b4d9c84c33a521098349e",
            "bc5a013d9d444ea5b1f7f77a82005bb3",
            "65c849018b4e4712aedc2b6e6d468f5b",
            "4620655e77204b218ea280209159d435",
            "0cf0909e28c4424484eab9410aaeea65",
            "8298beb56521435e9b9a80ff1d73297e",
            "23601d1866e3471a800f8f8a926afe7d",
            "1c794ccb097543f7bb6c344e64bb8969",
            "942d1542402f46469024f56b52458843",
            "37d33869ffac4c09b667111118401c8f"
          ]
        },
        "id": "K1_kqDmpTSGC",
        "outputId": "0e3ce418-2fef-4a1a-c45f-2848a29148a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /content/checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name | Type          | Params\n",
            "---------------------------------------\n",
            "0 | d    | Discriminator | 335 K \n",
            "1 | g    | Generator     | 406 K \n",
            "---------------------------------------\n",
            "741 K     Trainable params\n",
            "0         Non-trainable params\n",
            "741 K     Total params\n",
            "2.966     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name | Type          | Params\n",
            "---------------------------------------\n",
            "0 | d    | Discriminator | 335 K \n",
            "1 | g    | Generator     | 406 K \n",
            "---------------------------------------\n",
            "741 K     Trainable params\n",
            "0         Non-trainable params\n",
            "741 K     Total params\n",
            "2.966     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bb32e5ae18948b8887d3eb5b411029d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(rgan, train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEHG4cjBgIMO"
      },
      "source": [
        "## Call Finish on Exp logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_3-dK_FgF2m"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QrEvt1l-iBa9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7bb32e5ae18948b8887d3eb5b411029d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea5842f0171b4d9c84c33a521098349e",
              "IPY_MODEL_bc5a013d9d444ea5b1f7f77a82005bb3",
              "IPY_MODEL_65c849018b4e4712aedc2b6e6d468f5b"
            ],
            "layout": "IPY_MODEL_4620655e77204b218ea280209159d435"
          }
        },
        "ea5842f0171b4d9c84c33a521098349e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf0909e28c4424484eab9410aaeea65",
            "placeholder": "​",
            "style": "IPY_MODEL_8298beb56521435e9b9a80ff1d73297e",
            "value": "Epoch 0:  56%"
          }
        },
        "bc5a013d9d444ea5b1f7f77a82005bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23601d1866e3471a800f8f8a926afe7d",
            "max": 938,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c794ccb097543f7bb6c344e64bb8969",
            "value": 550
          }
        },
        "65c849018b4e4712aedc2b6e6d468f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_942d1542402f46469024f56b52458843",
            "placeholder": "​",
            "style": "IPY_MODEL_37d33869ffac4c09b667111118401c8f",
            "value": " 525/938 [00:28&lt;00:22, 18.72it/s, v_num=ngxp, g_loss_step=-.489, d_loss_step=1.810]"
          }
        },
        "4620655e77204b218ea280209159d435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "0cf0909e28c4424484eab9410aaeea65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8298beb56521435e9b9a80ff1d73297e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23601d1866e3471a800f8f8a926afe7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c794ccb097543f7bb6c344e64bb8969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "942d1542402f46469024f56b52458843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d33869ffac4c09b667111118401c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}